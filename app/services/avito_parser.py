# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å Avito (–ò–¥–µ—è #14: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)

–í–ù–ò–ú–ê–ù–ò–ï: –ü–∞—Ä—Å–∏–Ω–≥ Avito –º–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∞—Ç—å –∏—Ö Terms of Service.
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞ —Å–≤–æ–π —Ä–∏—Å–∫ –∏–ª–∏ –ø–æ–ª—É—á–∏—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π API –¥–æ—Å—Ç—É–ø.
"""
import aiohttp
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
import asyncio
import re
from urllib.parse import urljoin

from app.config import settings


class AvitoParserService:
    """–°–µ—Ä–≤–∏—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ Avito"""

    BASE_URL = "https://www.avito.ru"

    def __init__(self):
        self.enabled = settings.AVITO_PARSER_ENABLED
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
        }

    async def search_ads(
            self,
            query: str,
            category: Optional[str] = None,
            city: str = "moskva",
            limit: int = 20
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ Avito

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è (electronics, clothing, etc)
            city: –ì–æ—Ä–æ–¥
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        if not self.enabled:
            return []

        # –ú–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ Avito
        category_map = {
            "electronics": "elektronika",
            "clothing": "odezhda_obuv_aksessuary",
            "home": "tovary_dlya_doma_i_dachi",
            "hobbies": "hobbi_i_otdyh",
        }

        avito_category = category_map.get(category, "")

        # –§–æ—Ä–º–∏—Ä—É–µ–º URL
        if avito_category:
            url = f"{self.BASE_URL}/{city}/{avito_category}?q={query}"
        else:
            url = f"{self.BASE_URL}/{city}?q={query}"

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=self.headers) as response:
                    if response.status != 200:
                        print(f"‚ùå Avito parser error: HTTP {response.status}")
                        return []

                    html = await response.text()
                    ads = await self._parse_search_results(html, limit)

                    return ads

        except Exception as e:
            print(f"‚ùå Avito parser exception: {e}")
            return []

    async def _parse_search_results(self, html: str, limit: int) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        soup = BeautifulSoup(html, 'lxml')

        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏
        # –í–ù–ò–ú–ê–ù–ò–ï: –°–µ–ª–µ–∫—Ç–æ—Ä—ã –º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç!
        items = soup.select('[data-marker="item"]')[:limit]

        ads = []
        for item in items:
            try:
                ad_data = await self._parse_ad_item(item)
                if ad_data:
                    ads.append(ad_data)
            except Exception as e:
                print(f"‚ö†Ô∏è  Error parsing ad item: {e}")
                continue

        return ads

    async def _parse_ad_item(self, item) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_elem = item.select_one('[itemprop="name"]')
        if not title_elem:
            return None
        title = title_elem.get_text(strip=True)

        # –û–ø–∏—Å–∞–Ω–∏–µ
        description_elem = item.select_one('[class*="item-description"]')
        description = description_elem.get_text(strip=True) if description_elem else ""

        # –¶–µ–Ω–∞
        price_elem = item.select_one('[itemprop="price"]')
        price_text = price_elem.get('content') if price_elem else None
        price = self._parse_price(price_text) if price_text else None

        # –°—Å—ã–ª–∫–∞
        link_elem = item.select_one('a[itemprop="url"]')
        link = urljoin(self.BASE_URL, link_elem.get('href')) if link_elem else None

        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_elem = item.select_one('img[itemprop="image"]')
        image_url = img_elem.get('src') if img_elem else None

        # –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ
        location_elem = item.select_one('[class*="geo-georeferences"]')
        location = location_elem.get_text(strip=True) if location_elem else None

        return {
            "title": title,
            "description": description,
            "price": price,
            "link": link,
            "image_url": image_url,
            "location": location,
            "source": "avito"
        }

    def _parse_price(self, price_text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
        numbers = re.sub(r'\D', '', price_text)

        try:
            return int(numbers) if numbers else None
        except ValueError:
            return None

    async def download_image(self, image_url: str) -> Optional[bytes]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(image_url, headers=self.headers) as response:
                    if response.status == 200:
                        return await response.read()
        except Exception as e:
            print(f"‚ö†Ô∏è  Error downloading image: {e}")

        return None

    async def import_ad_to_bot(
            self,
            ad_data: Dict,
            user_id: int,
            category: str
    ) -> Dict:
        """
        –ò–º–ø–æ—Ä—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ –±–æ—Ç–∞

        Returns:
            –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        photo_data = None
        if ad_data.get("image_url"):
            photo_data = await self.download_image(ad_data["image_url"])

        return {
            "user_id": user_id,
            "category": category,
            "title": ad_data["title"][:150],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            "description": (
                f"{ad_data['description']}\n\n"
                f"üîó –ò—Å—Ç–æ—á–Ω–∏–∫: {ad_data.get('link', 'Avito')}"
            )[:500],
            "price": ad_data.get("price"),
            "photo_data": photo_data,
            "location_name": ad_data.get("location"),
        }


# Singleton instance
avito_parser = AvitoParserService()


# ==================== USAGE EXAMPLE ====================

async def example_usage():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""

    # –ü–æ–∏—Å–∫ iPhone –Ω–∞ Avito
    results = await avito_parser.search_ads(
        query="iPhone 13",
        category="electronics",
        city="moskva",
        limit=10
    )

    print(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(results)}")

    for ad in results:
        print(f"\nüì± {ad['title']}")
        print(f"üí∞ {ad['price']} ‚ÇΩ")
        print(f"üìç {ad['location']}")
        print(f"üîó {ad['link']}")


if __name__ == "__main__":
    asyncio.run(example_usage())